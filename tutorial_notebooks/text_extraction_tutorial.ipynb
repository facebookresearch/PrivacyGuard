{
  "metadata": {
    "language_info": {
      "name": "python",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "file_extension": ".py",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      }
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "isCinder": false,
      "display_name": "python3"
    },
    "operator_data": []
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "customInput": null,
        "originalKey": "1fed6040-365b-4bfb-a199-571cd77dfd91"
      },
      "source": [
        "# Text Extraction and Inclusion Analysis with PrivacyGuard\n",
        "\n",
        "## Introduction\n",
        "\n",
        "We showcase a text extraction and inclusion analysis attack using PrivacyGuard.\n",
        "Text extraction measures the ability to extract target text content from a given LLM, which\n",
        "can be used as a proxy to quantify memorization of that text.\n",
        "\n",
        "This tutorial will walk through the process of\n",
        "- Using PrivacyGuard's generation tooling to conduct extraction evals on small LLMs\n",
        "- Running TextInclusionAttack and TextInclusionAnalysis to measure extraction rates of the ENRON email dataset.\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "customInput": null,
        "originalKey": "be4a0320-1d21-4cbc-b476-b38ad5d8e116"
      },
      "source": [
        "import os\n",
        "\n",
        "working_directory = \"~/privacy_guard_working_directory\"\n",
        "\n",
        "working_directory_path = os.path.expanduser(working_directory)\n",
        "if not os.path.isdir(working_directory_path):\n",
        "    os.mkdir(working_directory_path)\n",
        "else:\n",
        "    print(f\"Working directory already exists: {working_directory_path}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "customInput": null,
        "originalKey": "90951dcf-33cd-4f91-8308-1577143f769c"
      },
      "source": [
        "# Preparing the Enron Email dataset\n",
        "\n",
        "In each experiment, we\n",
        "measure extraction rates with respect to 10,000 examples drawn from the Enron dataset, \n",
        "which is contained in the Pile (Gao et al., 2020)â€”the training\n",
        "dataset for both Pythia and GPT-Neo 1.3B\n",
        "\n",
        "To begin, download the May 7, 2015 version of the Enron dataset from https://www.cs.cmu.edu/~enron/\n",
        "\n",
        "Move the compressed file to ~/privacy_guard_working_directory, and decompress with the following command. \n",
        "(NOTE that the dataset is large, so decompressing will create a large nexted directory)\n",
        "```\n",
        "cd ~/privacy_guard_working_directory\n",
        "ls # Verify that enron_mail_20150507.tar.gz is located in the working directory\n",
        "tar -xvzf enron_mail_20150507.tar.gz\n",
        "```\n",
        "\n",
        "In unix, then decompress the file with 'tar -xvzf enron_mail_20150507.tar.gz'\n",
        "\n",
        "Once complete, check the directory structure\n",
        "```\n",
        "ls maildir\n",
        "```\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "customInput": null,
        "originalKey": "879764d9-465d-47de-bccc-ed95aa37eb47"
      },
      "source": [
        "Next, we'll load samples from the decompressed dataset to use in extraction testing. \n",
        "\n",
        "maildir/allen-p/_sent_mail/ is a directory, containing ~600 emails"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "customInput": null,
        "originalKey": "ed3ee916-e7dc-4f34-8d31-16ae2be40e06"
      },
      "source": [
        "from typing import Dict, List\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Defining variables for setting up extraction samples\n",
        "max_num_samples = 10\n",
        "prompt_length_characters = 200\n",
        "target_length_characters = 200\n",
        "sample_length = prompt_length_characters + target_length_characters\n",
        "\n",
        "\n",
        "# Pointing to samples to test extraction\n",
        "example_content_dir = working_directory_path + \"/maildir/allen-p/_sent_mail/\"\n",
        "extraction_targets: List[Dict[str, str]] = []\n",
        "\n",
        "\n",
        "num_targets = 0\n",
        "for filename in sorted(os.listdir(example_content_dir)):\n",
        "    file_path = os.path.join(example_content_dir, filename)\n",
        "\n",
        "    if os.path.isfile(file_path) and os.path.getsize(file_path) >= sample_length:\n",
        "        with open(file_path, \"r\") as file:\n",
        "            file_content = file.read()\n",
        "            print(len(file_content[0:prompt_length_characters]))\n",
        "            extraction_targets.append(\n",
        "                {\n",
        "                    \"prompt\": file_content[0:prompt_length_characters],\n",
        "                    \"target\": file_content[\n",
        "                        prompt_length_characters : prompt_length_characters\n",
        "                        + target_length_characters\n",
        "                    ],\n",
        "                    \"filename\": filename,\n",
        "                }\n",
        "            )\n",
        "        num_targets += 1\n",
        "        if num_targets >= max_num_samples:\n",
        "            break\n",
        "\n",
        "\n",
        "print(f\"Prepared extraction target with length: {len(extraction_targets)}\")\n",
        "\n",
        "extraction_targets_df = pd.DataFrame(extraction_targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "customInput": null,
        "originalKey": "164fb1d5-b74d-4ffd-8b3a-df54ebd347da"
      },
      "source": [
        "# Save the dataframe to a .jsonl file\n",
        "from privacy_guard.attacks.extraction.utils.data_utils import save_results\n",
        "\n",
        "extraction_targets_path = working_directory_path + \"/extraction_targets.jsonl\"\n",
        "\n",
        "if not os.path.isfile(extraction_targets_path):\n",
        "    save_results(\n",
        "        extraction_targets_df,\n",
        "        extraction_targets_path,\n",
        "        format=\"jsonl\",\n",
        "    )\n",
        "\n",
        "    print(f\"Saved extraction targets to jsonl file {extraction_targets_path}\")\n",
        "else:\n",
        "    print(f\"Extraction target file already exists as {extraction_targets_path}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "customInput": null,
        "originalKey": "ffaaf332-9259-4f8b-86eb-a053aaac27fc"
      },
      "source": [
        "# Preparing GenerationAttack\n",
        "\n",
        "Extraction targets df is now prepared to run extraction attacks, where we attempt to generate the target text from example models.\n",
        "\n",
        "\n",
        "We'll do this in 3 steps\n",
        "1. Load the Pythia-12B model and tokenizer from Huggingface\n",
        "2. Prepare the GenerationAttackCustomModel\n",
        "3. Execute the GenerationAttack using \"run_attack\"\n",
        "\n",
        "This next step will use PrivacyGuard to load the Pythia model. \n",
        "(Note: this step will take some time)\n",
        "\n",
        "\n",
        "After executing this tutorial, feel free to clone and experiment with other models and datasets. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "customInput": null,
        "originalKey": "bbfbec9c-da8e-49dd-878f-5ea2b352ed6d"
      },
      "source": [
        "from bento import fwdproxy\n",
        "from privacy_guard.attacks.extraction.predictors.huggingface_predictor import (\n",
        "    HuggingFacePredictor,\n",
        ")\n",
        "\n",
        "# 1) Create a HuggingFace predictor instance using the defined class\n",
        "model_name = \"EleutherAI/pythia-12b\"\n",
        "\n",
        "print(f\"Loading model '{model_name}' using HuggingFacePredictor...\")\n",
        "with fwdproxy():\n",
        "    huggingface_predictor = HuggingFacePredictor(\n",
        "        model_name=model_name,\n",
        "        device=\"cuda\",\n",
        "        model_kwargs={\"torch_dtype\": \"auto\"},  # Use appropriate dtype\n",
        "        tokenizer_kwargs={},\n",
        "    )\n",
        "\n",
        "print(f\"Loaded model '{huggingface_predictor.model_name}' from HuggingFace\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "customInput": null,
        "originalKey": "fbea32f7-47b9-41f4-8c11-b85050d2e826"
      },
      "source": [
        "from privacy_guard.attacks.extraction.generation_attack import GenerationAttack\n",
        "\n",
        "# 2) Prepare the GenerationAttackCustomModel\n",
        "generation_attack = GenerationAttack(\n",
        "    input_file=extraction_targets_path,  # The dataset to perform generation attack on\n",
        "    output_file=None,  # When specified, saves generations to file.\n",
        "    predictor=huggingface_predictor,  # Pass the predictor instead of model/tokenizer\n",
        "    input_column=\"prompt\",  # Column used as prompt for each generation\n",
        "    output_column=\"prediction\",\n",
        "    batch_size=4,\n",
        "    max_new_tokens=50,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "customInput": null,
        "originalKey": "7a65c0b2-5848-4cd0-a994-03e51c6c8199"
      },
      "source": [
        "# Running GenerationAttack\n",
        "\n",
        "Now that GenerationAttack has been configured and initialized, the we can perform the generation attack using \"run_attack\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "customInput": null,
        "originalKey": "f9b25be3-c4e6-429b-89ae-7ba622a760e9"
      },
      "source": [
        "# 3) Execute the GenerationAttack using \"run_attack\"\n",
        "\n",
        "attack_result = generation_attack.run_attack()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "customInput": null,
        "originalKey": "4746d6be-7799-4577-ae8f-d1662cae40a0"
      },
      "source": [
        "# 3) Analysis\n",
        "\n",
        "Now that the generation attack is complete, we can perform Privacy Analysis to compute the extraction rate of the dataset. \n",
        "\n",
        "We'll look at the longest common substring score for each sample in the dataset, alonside the % of the target extracted. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "customInput": null,
        "originalKey": "4f09bcd6-cff7-45af-a572-ebbe4ec031fc"
      },
      "source": [
        "from typing import Any, Dict, List\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "from privacy_guard.analysis.extraction.text_inclusion_analysis_node import (\n",
        "    TextInclusionAnalysisNode,\n",
        ")\n",
        "\n",
        "attack_result.lcs_bound_config = None\n",
        "\n",
        "analysis_node = TextInclusionAnalysisNode(analysis_input=attack_result)\n",
        "\n",
        "results = analysis_node.run_analysis()\n",
        "\n",
        "if results.longest_common_substring is not None:\n",
        "    lcs_results = list(results.longest_common_substring)\n",
        "\n",
        "    displays = []\n",
        "\n",
        "    def display_result(\n",
        "        displays: List[Dict[str, Any]], lcs_dict: Dict[str, Any], augmented_row\n",
        "    ):\n",
        "        lcs_target = list(lcs_dict.keys())[0]\n",
        "\n",
        "        displays.append(\n",
        "            {\n",
        "                \"lcs\": lcs_dict[lcs_target],\n",
        "                \"\\% extracted\": 100 * lcs_dict[lcs_target] / len(lcs_target),\n",
        "                \"prediction\": augmented_row[\"prediction\"],\n",
        "                \"target\": augmented_row[\"target\"],\n",
        "            }\n",
        "        )\n",
        "\n",
        "    for lcs_dict, augmented_row in zip(\n",
        "        lcs_results, results.augmented_output_dataset.T.to_dict().values()\n",
        "    ):\n",
        "        display_result(\n",
        "            displays=displays, lcs_dict=lcs_dict, augmented_row=augmented_row\n",
        "        )\n",
        "\n",
        "    display(pd.DataFrame(displays))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "customInput": null,
        "originalKey": "1616d994-1f1e-4c38-99e9-df499e2cf903"
      },
      "source": [
        "# Summary\n",
        "\n",
        "We showcased a text extraction and inclusion analysis attack using PrivacyGuard. \n",
        "Text extraction measures the ability to extract target text content from a given LLM, which can be used as a proxy to quantify memorization of that text.\n",
        "\n",
        "This tutorial will walk through the process of\n",
        "\n",
        "1. Preparing the Enron email dataset to measure its memorization in the Pythia-12B model\n",
        "2. Using PrivacyGuard's generation tooling to load the model and perform extraction attacks\n",
        "3. Running TextInclusionAttack and TextInclusionAnalysis to measure extraction rates of the ENRON email dataset, and aggregating the extraction rates for the sample dataset. \n",
        "\n",
        "Utilize this tutorial as a base for performing extraction attacks for custom models and datasets. \n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "customInput": null,
        "originalKey": "8b12687c-1a92-40d1-ba36-c3932fbfa7c0"
      },
      "source": [
        ""
      ]
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5
}
